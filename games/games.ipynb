{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial sequential games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tic-Tac-Toe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from enum import Enum\n",
    "from typing import Any, NamedTuple, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "TIC_TAC_TOE = \"\"\"\n",
    " | | \n",
    "-----\n",
    " | | \n",
    "-----\n",
    " | | \n",
    "\"\"\"\n",
    "\n",
    "class State:\n",
    "    def __init__(self, array: ArrayLike):\n",
    "        self._array = array\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(tuple(self._array.astype(int).flatten()))\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return np.all(np.equal(self._array, other._array))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self._array)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self._array)\n",
    "    \n",
    "    @property\n",
    "    def array(self):\n",
    "        return self._array\n",
    "    \n",
    "    def copy(self):\n",
    "        return State(self._array.copy())\n",
    "    \n",
    "class Player(Enum):\n",
    "    CrossPlayer = 1\n",
    "    CirclePlayer = 2\n",
    "    \n",
    "class Action(NamedTuple):\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self, tic_tac_toe_str: str = TIC_TAC_TOE):\n",
    "        tic_tac_toe = []\n",
    "        for y, line in enumerate(tic_tac_toe_str.split(\"\\n\")):\n",
    "            row = []\n",
    "            for c in line:\n",
    "                if c == \" \":\n",
    "                    row.append(0)  # spaces are 0s\n",
    "                else:\n",
    "                    row.append(0.7)  # walls are 0.7s\n",
    "            tic_tac_toe.append(row)\n",
    "        self._tic_tac_toe = np.array(tic_tac_toe[1:-1], dtype=np.float32)\n",
    "        self._ax = None\n",
    "        self._fig = None\n",
    "        self._image = None\n",
    "        \n",
    "    def reset(self):\n",
    "        return State(np.zeros(shape=[3, 3], dtype=np.int32))\n",
    "    \n",
    "    def get_next_state(self, state: State, action: Tuple[Player, Action]) -> Tuple[State, float, bool]:\n",
    "        assert state.array[action[1].x][action[1].y] == 0\n",
    "        next_state = state.copy()\n",
    "        next_state.array[action[1].x][action[1].y] = action[0].value\n",
    "        if (np.asarray(np.prod(next_state.array, axis=0) == action[0].value**3).sum() > 0 or\n",
    "            np.asarray(np.prod(next_state.array, axis=1) == action[0].value**3).sum() > 0 or\n",
    "            np.prod(np.diagonal(next_state.array)) == action[0].value**3 or\n",
    "            np.prod(np.diagonal(np.fliplr(next_state.array))) == action[0].value**3):\n",
    "            return next_state, -2 * action[0].value + 3, True\n",
    "        elif np.sum(np.asarray(next_state.array == 0).nonzero()) == 0:\n",
    "            return next_state, 0, True\n",
    "        else:\n",
    "            return next_state, 0, False\n",
    "    \n",
    "    def render(self, state: State) -> Any:\n",
    "        if self._ax is None:\n",
    "            fig, ax = plt.subplots(1)\n",
    "            fig.canvas.set_window_title(\"tic-tac-toe\")\n",
    "            ax.set_aspect(\"equal\")  # set the x and y axes to the same scale\n",
    "            plt.xticks([])  # remove the tick marks by setting to an empty list\n",
    "            plt.yticks([])  # remove the tick marks by setting to an empty list\n",
    "            ax.invert_yaxis()  # invert the y-axis so the first row of data is at the top\n",
    "            self._ax = ax\n",
    "            self._fig = fig\n",
    "            plt.ion()\n",
    "        if self._image is None:\n",
    "            self._image = self._ax.imshow(self._tic_tac_toe, cmap='Greys', vmin=0, vmax=1)\n",
    "        else:\n",
    "            self._image.set_data(self._tic_tac_toe)\n",
    "        for row in range(3):\n",
    "            for col in range(3):\n",
    "                if state.array[row][col] == 1:\n",
    "                    self._ax.scatter(2 * col, 2 * row, s=500, c='blue', marker='x')\n",
    "                elif state.array[row][col] == 2:\n",
    "                    self._ax.scatter(2 * col, 2 * row, s=500, facecolors='none', edgecolors='red')\n",
    "        display(self._fig)\n",
    "        clear_output(wait = True)\n",
    "        plt.pause(1)\n",
    "        \n",
    "tic_tac_toe = TicTacToe()\n",
    "tic_tac_toe.render(tic_tac_toe.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [minimax](https://en.wikipedia.org/wiki/Minimax) algorithm is used to find optimal non-cooperative 2-player strategies where\n",
    "one player will try to maximize its own final score knowing that it will alternate with another player which will\n",
    "try to minimize the first player's score.\n",
    "The algorithm will then alternate maximization and minimization operations, hence its name.\n",
    "Intuitively, the first player will try to maximize the minimum score it can get because of the other player trying\n",
    "to make it lose the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![minimax](./img/Minimax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the tree structure that will alternate maximizing player nodes and minimizing player node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict\n",
    "from typing import Any, Tuple, List\n",
    "\n",
    "class Tree:\n",
    "    class Node:\n",
    "        def __init__(self,\n",
    "                     data: Any,\n",
    "                     max_player: bool = True,\n",
    "                     terminal: bool = False,\n",
    "                     terminal_value: float = 0,\n",
    "                     best_child: Tree.Node = None):\n",
    "            self._data = data\n",
    "            self._max_player = max_player\n",
    "            self._terminal = terminal\n",
    "            self._terminal_value = terminal_value\n",
    "            self._best_child = best_child\n",
    "            self._children: List[Tuple[Tree.Node, str]] = []\n",
    "            \n",
    "        @property\n",
    "        def data(self):\n",
    "            return self._data\n",
    "        \n",
    "        @property\n",
    "        def max_player(self):\n",
    "            return self._max_player\n",
    "        \n",
    "        @property\n",
    "        def terminal(self):\n",
    "            return self._terminal\n",
    "        \n",
    "        @property\n",
    "        def terminal_value(self):\n",
    "            return self._terminal_value\n",
    "        \n",
    "        @property\n",
    "        def best_child(self):\n",
    "            return self._best_child\n",
    "        \n",
    "        def __eq__(self, other: Tree.Node):\n",
    "            return self._data.__eq__(other._data)\n",
    "        \n",
    "        def __hash__(self):\n",
    "            return hash(self._data)\n",
    "        \n",
    "        def __str__(self):\n",
    "            return str(self._data)\n",
    "        \n",
    "        def __repr__(self):\n",
    "            return 'Node(data: {}, max_player: {}, terminal: {}, best child: {})'.format(\n",
    "                repr(self._data),\n",
    "                'true' if self._max_player else 'false',\n",
    "                'true [{}]'.format(self._terminal_value) if self._terminal else 'false',\n",
    "                repr(self._child._data) if self._child is not None else None)\n",
    "            \n",
    "    def __init__(self):\n",
    "        self._nodes: Dict[Any, Tree.Node] = {}\n",
    "    \n",
    "    def get_node(self, data: Any):\n",
    "        if data not in self._nodes:\n",
    "            self._nodes[data] = Tree.Node(data)\n",
    "        return self._nodes[data]\n",
    "        \n",
    "    def get_children(self, node: Node) -> List[Tuple[Node, str]]:\n",
    "        if node.data not in self._nodes or len(node._children) == 0:\n",
    "            node._children = list(self.generate_children(node))\n",
    "            assert all((c[0].max_player and not node.max_player) or\n",
    "                       (not c[0].max_player and node.max_player)\n",
    "                       for c in node._children)\n",
    "            self._nodes[node.data] = node\n",
    "        return self._nodes[node.data]._children\n",
    "    \n",
    "    def generate_children(self, node: Node) -> List[Tuple[Node, str]]:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def is_terminal(self, node: Node) -> bool:\n",
    "        return node.terminal\n",
    "    \n",
    "    def render(self, node: Node) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Know, the code of the minimax algorithm, as described [there](https://en.wikipedia.org/wiki/Minimax#Pseudocode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def minimax(node : Tree.Node,\n",
    "            tree: Tree,\n",
    "            depth : int,\n",
    "            maximizing_player : bool,\n",
    "            evaluate : Callable[[Tree.Node], float]):\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/minimax.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeTree(Tree):\n",
    "    def __init__(self, tic_tac_toe):\n",
    "        super().__init__()\n",
    "        self._tic_tac_toe = tic_tac_toe\n",
    "    \n",
    "    def generate_children(self, node: Tree.Node) -> List[Tuple[Tree.Node, str]]:\n",
    "        state = node.data\n",
    "        ### WRITE YOUR CODE HERE\n",
    "        # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    \n",
    "    def render(self, node: Tree.Node) -> None:\n",
    "        self._tic_tac_toe.render(node.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/tic_tac_toe_tree.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic_tac_toe = TicTacToe(TIC_TAC_TOE)\n",
    "tic_tac_toe_tree = TicTacToeTree(tic_tac_toe)\n",
    "\n",
    "minimax(node=Tree.Node(data=tic_tac_toe.reset()),\n",
    "        tree = tic_tac_toe_tree,\n",
    "        depth=1000,\n",
    "        maximizing_player=True,\n",
    "        evaluate = lambda n : n.terminal_value)\n",
    "\n",
    "node = tic_tac_toe_tree.get_node(data=tic_tac_toe.reset())\n",
    "tic_tac_toe.render(node.data)\n",
    "\n",
    "while not node.terminal:\n",
    "    print('Action: {}'.format(node.best_child[1]))\n",
    "    node = node.best_child[0]\n",
    "    tic_tac_toe.render(node.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha-Beta Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Alpha-Beta Pruning](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) algorithm is a popular optimal algorithm\n",
    "to solve non-cooperative 2-player sequential games that improves over minimax by cutting search branches that are known to\n",
    "be useless for one's player strategy to be improved.\n",
    "To do so, the algorithm maintains maximum (_aka_ $\\alpha$) and minimum (_aka_ $\\beta$) values on, respectively, the maximizing\n",
    "player's terminal score and the minimizing player's terminal score.\n",
    "Those bounds allow the algorithm to stop exploring one player's node's subtrees (i.e. pruning the corresponding branches)\n",
    "whenever the already discovered subtrees are sufficient to prove that the other player will necessarily choose a different option\n",
    "than the one leading to the first player's node's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alpha-Beta Pruning](img/AB_pruning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pseudocode of the Alpha-Beta Pruning algorithm is described [there](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning#Pseudocode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def alphabeta(node : Tree.Node,\n",
    "              tree: Tree,\n",
    "              depth : int,\n",
    "              alpha : float,\n",
    "              beta : float,\n",
    "              maximizing_player : bool,\n",
    "              evaluate : Callable[[Tree.Node], float]):\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/alphabeta.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic_tac_toe = TicTacToe(TIC_TAC_TOE)\n",
    "tic_tac_toe_tree = TicTacToeTree(tic_tac_toe)\n",
    "\n",
    "alphabeta(node=Tree.Node(data=tic_tac_toe.reset()),\n",
    "          tree = tic_tac_toe_tree,\n",
    "          depth=1000,\n",
    "          alpha=-float(\"inf\"),\n",
    "          beta=float(\"inf\"),\n",
    "          maximizing_player=True,\n",
    "          evaluate = lambda n : n.terminal_value)\n",
    "\n",
    "node = tic_tac_toe_tree.get_node(data=tic_tac_toe.reset())\n",
    "tic_tac_toe.render(node.data)\n",
    "\n",
    "while not node.terminal:\n",
    "    print('Action: {}'.format(node.best_child[1]))\n",
    "    node = node.best_child[0]\n",
    "    tic_tac_toe.render(node.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing against a random player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tic_tac_toe = TicTacToe(TIC_TAC_TOE)\n",
    "tic_tac_toe_tree = TicTacToeTree(tic_tac_toe)\n",
    "\n",
    "def call_alphabeta_pruning(tic_tac_toe_tree: TicTacToeTree,\n",
    "                           node: Tree.Node) -> None:\n",
    "    alphabeta(node=node,\n",
    "              tree = tic_tac_toe_tree,\n",
    "              depth=1000,\n",
    "              alpha=-float(\"inf\"),\n",
    "              beta=float(\"inf\"),\n",
    "              maximizing_player=True,\n",
    "              evaluate = lambda n : n.terminal_value)\n",
    "    \n",
    "def call_random_player(tic_tac_toe_tree: TicTacToeTree,\n",
    "                       node: Tree.Node) -> None:\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    pass\n",
    "\n",
    "node = tic_tac_toe_tree.get_node(data=tic_tac_toe.reset())\n",
    "tic_tac_toe.render(node.data)\n",
    "\n",
    "while not node.terminal:\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "        \n",
    "    node = node.best_child[0]\n",
    "    tic_tac_toe.render(node.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/alphabeta_vs_random.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing _optimally_ against a random player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that the opponent is playing randomly, we can exploit the knowledge of its policy to optimize our own strategy.\n",
    "For this, we can model our own process choice as a Markov Decision Process and solve the game _from our perspective_ by using\n",
    "an MDP algorithm like RTDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict\n",
    "\n",
    "class ProbabilisticGameGraph:\n",
    "    class StateNode:\n",
    "        def __init__(self, data: Tree.Node):\n",
    "            self._data = data\n",
    "            self._best_action = None\n",
    "            self._best_value = None\n",
    "            self._successors: List[ProbabilisticGameGraph.ActionNode] = []\n",
    "            \n",
    "        @property\n",
    "        def data(self):\n",
    "            return self._data\n",
    "        \n",
    "        @property\n",
    "        def best_action(self):\n",
    "            return self._best_action\n",
    "        \n",
    "        @property\n",
    "        def best_value(self):\n",
    "            return self._best_value\n",
    "            \n",
    "        def __eq__(self, other: ProbabilisticGameGraph.StateNode):\n",
    "            return self._data.__eq__(other._data)\n",
    "        \n",
    "        def __hash__(self):\n",
    "            return hash(self._data)\n",
    "        \n",
    "        def __str__(self):\n",
    "            return str(self._data)\n",
    "        \n",
    "        def __repr__(self):\n",
    "            return 'Node(data: {}, best action: {}, best value: {})'.format(\n",
    "                repr(self._data),\n",
    "                repr(self._best_action) if self._best_action is not None else None,\n",
    "                repr(self._best_value) if self._best_value is not None else None)\n",
    "    \n",
    "    class ActionNode:\n",
    "        def __init__(self, data: Any):\n",
    "            self._data = data\n",
    "            self._successors: List[Tuple[ProbabilisticGameGraph.StateNode, float]] = []\n",
    "            \n",
    "        @property\n",
    "        def data(self):\n",
    "            return self._data\n",
    "            \n",
    "        def __eq__(self, other: ProbabilisticGameGraph.ActionNode):\n",
    "            return self._data.__eq__(other._data)\n",
    "        \n",
    "        def __hash__(self):\n",
    "            return hash(self._data)\n",
    "        \n",
    "        def __str__(self):\n",
    "            return str(self._data)\n",
    "        \n",
    "        def __repr__(self):\n",
    "            return 'ActionNode(data: {})'.format(\n",
    "                repr(self._data))\n",
    "    \n",
    "    def __init__(self,\n",
    "                 game_tree: Tree,\n",
    "                 opponent_policy: Callable[[Tree.Node],\n",
    "                                           List[Tuple[float, Tree.Node]]]):\n",
    "        self._nodes: Dict[Any, ProbabilisticGameGraph.StateNode] = {}\n",
    "        self._game_tree = game_tree\n",
    "        self._opponent_policy = opponent_policy\n",
    "    \n",
    "    def get_node(self, data: Any):\n",
    "        if data not in self._nodes:\n",
    "            self._nodes[data] = ProbabilisticGameGraph.StateNode(data)\n",
    "        return self._nodes[data]\n",
    "        \n",
    "    def get_successors(self, node: StateNode) -> List[ActionNode]:\n",
    "        if node.data not in self._nodes or len(node._successors) == 0:\n",
    "            node._successors = list(self.generate_successors(node))\n",
    "            self._nodes[node.data] = node\n",
    "        return self._nodes[node.data]._successors\n",
    "    \n",
    "    def generate_successors(self, node: StateNode) -> List[ActionNode]:\n",
    "        ### WRITE YOUR CODE HERE\n",
    "        # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "        pass\n",
    "    \n",
    "    def is_goal(self, node: StateNode) -> bool:\n",
    "        return self._game_tree.is_terminal(node.data)\n",
    "    \n",
    "    def render(self, node: StateNode) -> None:\n",
    "        self._game_tree.render(node.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/probabilistic_game_graph.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use RTDP as our MDP solver, as described in Algorthm 1 in [this paper](https://ftp.cs.ucla.edu/pub/stat_ser/R319.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Set\n",
    "\n",
    "class GameRTDP:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        graph: ProbabilisticGameGraph,\n",
    "        heuristic: Optional[\n",
    "            Callable[[ProbabilisticGameGraph.StateNode], float]\n",
    "        ] = None,\n",
    "        max_steps: int = 1000,\n",
    "        trials_number: int = 100,\n",
    "        verbose: bool = False,\n",
    "        render: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        self._graph = graph\n",
    "        self._heuristic = (\n",
    "            (lambda _: 0.0) if heuristic is None else heuristic\n",
    "        )\n",
    "        self._max_steps = max_steps\n",
    "        self._trials_number = trials_number\n",
    "        self._verbose = verbose\n",
    "        self._render = render\n",
    "        self._values = {}\n",
    "\n",
    "    def solve_from(self, tree_node: Tree.Node) -> None:\n",
    "        \n",
    "        def extender(node, explored):\n",
    "            actions = []\n",
    "            for action in self._graph.get_successors(node):\n",
    "                for next_state, _ in action._successors:\n",
    "                    if next_state not in explored:\n",
    "                        if self._verbose:\n",
    "                            print('New node {}'.format(str(next_state)))\n",
    "                        next_state._best_value = self._heuristic(next_state)\n",
    "                        explored.add(next_state)\n",
    "                actions.append(action)\n",
    "            return actions\n",
    "        \n",
    "        ### WRITE YOUR CODE HERE\n",
    "        # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    \n",
    "    def trial(self,\n",
    "              root_node: ProbabilisticGameGraph.StateNode,\n",
    "              extender : Callable[[ProbabilisticGameGraph.StateNode,\n",
    "                                   Set[ProbabilisticGameGraph.StateNode]],\n",
    "                                  List[ProbabilisticGameGraph.ActionNode]],\n",
    "              explored: Set[ProbabilisticGameGraph.StateNode]) -> None:\n",
    "        \n",
    "        ### WRITE YOUR CODE HERE\n",
    "        # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "        pass\n",
    "    \n",
    "    def greedy_action(self,\n",
    "                      node: ProbabilisticGameGraph.StateNode,\n",
    "                      extender : Callable[[ProbabilisticGameGraph.StateNode,\n",
    "                                           Set[ProbabilisticGameGraph.StateNode]],\n",
    "                                          List[ProbabilisticGameGraph.ActionNode]],\n",
    "                      explored: Set[ProbabilisticGameGraph.StateNode]) -> Tuple[ProbabilisticGameGraph.ActionNode, float]:\n",
    "        ### WRITE YOUR CODE HERE\n",
    "        # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "        pass\n",
    "    \n",
    "    def update(self,\n",
    "               state_node: ProbabilisticGameGraph.StateNode,\n",
    "               action_node: ProbabilisticGameGraph.ActionNode,\n",
    "               value: float) -> None:\n",
    "        ### WRITE YOUR CODE HERE\n",
    "        # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "        pass\n",
    "    \n",
    "    def pick_next_state(self, action_node: ProbabilisticGameGraph.ActionNode) -> ProbabilisticGameGraph.StateNode:\n",
    "        ### WRITE YOUR CODE HERE\n",
    "        # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/game_rtdp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tic_tac_toe = TicTacToe(TIC_TAC_TOE)\n",
    "tic_tac_toe_tree = TicTacToeTree(tic_tac_toe)\n",
    "\n",
    "def heuristic(n: ProbabilisticGameGraph.StateNode) -> float:\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    pass\n",
    "\n",
    "def call_game_rtdp(game_graph: ProbabilisticGameGraph,\n",
    "                   node: Tree.Node,\n",
    "                   max_value: float) -> None:\n",
    "    rtdp = GameRTDP(\n",
    "        graph=game_graph,\n",
    "        heuristic = lambda n : heuristic(n),\n",
    "        max_steps=1000,\n",
    "        trials_number=100,\n",
    "        verbose=False,\n",
    "        render=False)\n",
    "    rtdp.solve_from(node)\n",
    "    \n",
    "def call_random_player(tic_tac_toe_tree: TicTacToeTree,\n",
    "                       node: Tree.Node) -> None:\n",
    "    node._best_child = random.sample(tic_tac_toe_tree.get_children(node), 1)[0]\n",
    "    \n",
    "def random_player_policy(node: Tree.Node) -> List[Tuple[float, Tree.Node]]:\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    pass\n",
    "\n",
    "node = tic_tac_toe_tree.get_node(data=tic_tac_toe.reset())\n",
    "tic_tac_toe.render(node.data)\n",
    "\n",
    "game_graph = ProbabilisticGameGraph(game_tree=tic_tac_toe_tree,\n",
    "                                    opponent_policy=random_player_policy)\n",
    "\n",
    "while not node.terminal:\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "        \n",
    "    node = node.best_child[0]\n",
    "    tic_tac_toe.render(node.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/rtdp_vs_random.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to epic combats: RTDP vs RTDP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic_tac_toe = TicTacToe(TIC_TAC_TOE)\n",
    "tic_tac_toe_tree = TicTacToeTree(tic_tac_toe)\n",
    "\n",
    "def opponent_policy(tree_node: Tree.Node,\n",
    "                    opponent_game_graph: ProbabilisticGameGraph) -> List[Tuple[float, Tree.Node]]:\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    pass\n",
    "\n",
    "def heuristic(n: ProbabilisticGameGraph.StateNode) -> float:\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    pass\n",
    "\n",
    "def call_game_rtdp(game_tree: Tree,\n",
    "                   node: Tree.Node,\n",
    "                   opponent_game_graph: ProbabilisticGameGraph,\n",
    "                   max_value: float,\n",
    "                   max_or_min_player: bool) -> None:\n",
    "    game_graph = ProbabilisticGameGraph(\n",
    "        game_tree=game_tree,\n",
    "        opponent_policy=lambda tree_node : opponent_policy(tree_node, opponent_game_graph)\n",
    "    )\n",
    "    rtdp = GameRTDP(\n",
    "        graph=game_graph,\n",
    "        heuristic = lambda n : heuristic(n),\n",
    "        max_steps=1000,\n",
    "        trials_number=100,\n",
    "        verbose=False,\n",
    "        render=False)\n",
    "    rtdp.solve_from(node)\n",
    "    return game_graph\n",
    "\n",
    "node = tic_tac_toe_tree.get_node(data=tic_tac_toe.reset())\n",
    "tic_tac_toe.render(node.data)\n",
    "current_game_graph = None\n",
    "\n",
    "while not node.terminal:\n",
    "    print('Player {}\\'s turn'.format(\n",
    "        'Cross' if node.max_player else 'Circle'\n",
    "    ))\n",
    "    current_game_graph = call_game_rtdp(\n",
    "        tic_tac_toe_tree,\n",
    "        node,\n",
    "        current_game_graph,\n",
    "        1,\n",
    "        node.max_player\n",
    "    )\n",
    "    \n",
    "    node = node.best_child[0]\n",
    "    tic_tac_toe.render(node.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/rtdp_vs_rtdp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying a more difficult game: connect-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muzero.games.connect4 import Connect4\n",
    "\n",
    "connect4 = Connect4()\n",
    "connect4.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class Board:\n",
    "    def __init__(self, board: ArrayLike):\n",
    "        self._board = board\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(tuple(self._board.astype(int).flatten()))\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return np.all(np.equal(self._board, other._board))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self._board)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self._board)\n",
    "    \n",
    "    @property\n",
    "    def board(self):\n",
    "        return self._board\n",
    "    \n",
    "    def copy(self):\n",
    "        return Board(self._board.copy())\n",
    "    \n",
    "\n",
    "class Connect4Tree(Tree):\n",
    "    # We will store the Connect4 boards in the tree nodes\n",
    "    # I.e: Tree.Node._data is a Board (i.e. hashable numpy array) as defined in the Connect4 class\n",
    "            \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._ax = None\n",
    "        self._fig = None\n",
    "        self._image = None\n",
    "    \n",
    "    def reset(self) -> Tree.Node:\n",
    "        connect4 = Connect4()\n",
    "        connect4.reset()\n",
    "        return self.get_node(data=Board(connect4.board))\n",
    "    \n",
    "    def generate_children(self, node: Tree.Node) -> List[Tuple[Tree.Node, str]]:\n",
    "        connect4 = Connect4()\n",
    "        connect4.board = node.data.board\n",
    "        ### WRITE YOUR CODE HERE\n",
    "        # If you get stuck, uncomment the line in the next cell to load a solution.\n",
    "    \n",
    "    def render(self, node: Tree.Node) -> None:\n",
    "        board_to_render = np.zeros(shape=(2 * node.data.board[::-1].shape[0] + 1,\n",
    "                                          2 * node.data.board[::-1].shape[1] + 1),\n",
    "                                   dtype=np.float32)\n",
    "        \n",
    "        for r in range(int(board_to_render.shape[0] / 2) + 1):\n",
    "            board_to_render[2*r,:] = 0.7 * np.ones(board_to_render.shape[1])\n",
    "        for c in range(int(board_to_render.shape[1] / 2) + 1):\n",
    "            board_to_render[:,2*c] = 0.7 * np.ones(board_to_render.shape[0])\n",
    "            \n",
    "        if self._ax is None:\n",
    "            fig, ax = plt.subplots(1)\n",
    "            fig.canvas.set_window_title(\"connect-4\")\n",
    "            ax.set_aspect(\"equal\")  # set the x and y axes to the same scale\n",
    "            plt.xticks([])  # remove the tick marks by setting to an empty list\n",
    "            plt.yticks([])  # remove the tick marks by setting to an empty list\n",
    "            ax.invert_yaxis()  # invert the y-axis so the first row of data is at the top\n",
    "            self._ax = ax\n",
    "            self._fig = fig\n",
    "            plt.ion()\n",
    "        if self._image is None:\n",
    "            self._image = self._ax.imshow(board_to_render, cmap='Greys', vmin=0, vmax=1)\n",
    "        else:\n",
    "            self._image.set_data(board_to_render)\n",
    "        \n",
    "        for r in range(node.data.board[::-1].shape[0]):\n",
    "            for c in range(node.data.board[::-1].shape[1]):\n",
    "                if node.data.board[::-1][r,c] == 1:\n",
    "                    self._ax.scatter(2*c + 1, 2*r + 1, facecolors='green', edgecolors='green')\n",
    "                elif node.data.board[::-1][r,c] == -1:\n",
    "                    self._ax.scatter(2*c + 1, 2*r + 1, facecolors='red', edgecolors='red')\n",
    "        \n",
    "        display(self._fig)\n",
    "        clear_output(wait = True)\n",
    "        plt.pause(1)\n",
    "\n",
    "connect4_tree = Connect4Tree()\n",
    "connect4_tree.render(connect4_tree.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/connect4_tree.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect4_tree = Connect4Tree()\n",
    "\n",
    "node = connect4_tree.reset()\n",
    "connect4_tree.render(node)\n",
    "\n",
    "while not node.terminal:\n",
    "    \n",
    "    if node.best_child is None:\n",
    "        connect4_tree = Connect4Tree()\n",
    "        alphabeta(node=node,\n",
    "              tree = connect4_tree,\n",
    "              depth=5,\n",
    "              alpha=-float(\"inf\"),\n",
    "              beta=float(\"inf\"),\n",
    "              maximizing_player=True,\n",
    "              evaluate = lambda n : n.terminal_value\n",
    "        )\n",
    "        \n",
    "#     print('Action: {}'.format(node.best_child[1]))\n",
    "    node = node.best_child[0]\n",
    "    connect4_tree.render(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MuZero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MuZero](https://www.deepmind.com/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules) is a popular algorithm for optimizing\n",
    "non-cooperative 2-player sequential games using [Monte-Carlo Tree Search](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search)\n",
    "and deep-learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MCTS](img/MCTS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MuZero](img/muzero.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd muzero/\n",
    "!pip install -r requirements.txt\n",
    "!pip uninstall -y pyarrow\n",
    "%load_ext tensorboard\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./muzero/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd muzero/\n",
    "!python muzero.py connect4 '{\"training_steps\": 100}'\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.path.abspath('')\n",
    "muzero_dir = os.path.join(current_dir, 'muzero')\n",
    "%env PYTHONPATH=$muzero_dir:$current_dir\n",
    "\n",
    "import sys\n",
    "sys.path.append(muzero_dir)\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "from muzero import MuZero\n",
    "from games.connect4 import MuZeroConfig, Game\n",
    "\n",
    "config = MuZeroConfig()\n",
    "config.training_steps = 100\n",
    "muzero = MuZero('connect4', config)\n",
    "muzero.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b81519d285639899e6ffbf246c769949a19cca29f480f5c915279ae591fdfb44"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
